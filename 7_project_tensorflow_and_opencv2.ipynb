{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T00:17:39.272629100Z",
     "start_time": "2026-01-16T00:17:33.006905900Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install Pillow",
   "id": "7e762525f9b49ada",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\code\\pythonproject\\.venv\\lib\\site-packages (12.1.0)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T00:17:43.177005400Z",
     "start_time": "2026-01-16T00:17:41.244350500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from logging import exception\n",
    "\n",
    "from fontTools.misc.psOperators import ps_string\n",
    "\n",
    "# pip 설치 시도\n",
    "subprocess.check_call([sys.executable, \"-m\", \"ensurepip\", \"--default-pip\"])\n",
    "# Pillow 설치\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"Pillow\"])"
   ],
   "id": "ca9c9fcfaa547b3c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T00:17:45.582309600Z",
     "start_time": "2026-01-16T00:17:44.967204200Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install pygame",
   "id": "961d3ae42b9ec9f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in c:\\code\\pythonproject\\.venv\\lib\\site-packages (2.6.1)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T00:17:48.049861700Z",
     "start_time": "2026-01-16T00:17:47.132934400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pygame\n",
    "import os\n",
    "\n",
    "pygame.mixer.init()\n",
    "\n",
    "# 윈도우 기본 미디어 폴더 경로\n",
    "win_media_path = \"C:/Windows/Media/\"\n",
    "\n",
    "sound_correct = pygame.mixer.Sound(win_media_path + \"Speech On.wav\")\n",
    "sound_wrong = pygame.mixer.Sound(win_media_path + \"Speech Misrecognition.wav\")"
   ],
   "id": "282f1aa4ff6dc262",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Code\\PythonProject\\.venv\\Lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.13.11)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T02:31:08.305533200Z",
     "start_time": "2026-01-16T02:31:08.289365700Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b028838b9fc0e894",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-16T03:27:11.627814400Z",
     "start_time": "2026-01-16T03:23:27.260187700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "train_images = train_images.reshape(-1, 28, 28, 1)\n",
    "test_images = test_images.reshape(-1, 28, 28, 1)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    zoom_range=0.1,\n",
    "    shear_range=0.2\n",
    ")\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(28, 28, 1)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(56, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(datagen.flow(train_images, train_labels, batch_size=32),\n",
    "          epochs=20)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "model.save('tensorflow_model.keras')\n",
    "print('\\n테스트 정확도:', test_acc)"
   ],
   "id": "6a90c3c77c4ee105",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 16ms/step - accuracy: 0.8190 - loss: 0.5639\n",
      "Epoch 2/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 5ms/step - accuracy: 0.9164 - loss: 0.2709\n",
      "Epoch 3/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 5ms/step - accuracy: 0.9320 - loss: 0.2198\n",
      "Epoch 4/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 6ms/step - accuracy: 0.9396 - loss: 0.1927\n",
      "Epoch 5/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 5ms/step - accuracy: 0.9453 - loss: 0.1772\n",
      "Epoch 6/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 5ms/step - accuracy: 0.9487 - loss: 0.1659\n",
      "Epoch 7/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 5ms/step - accuracy: 0.9527 - loss: 0.1548\n",
      "Epoch 8/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 5ms/step - accuracy: 0.9548 - loss: 0.1459\n",
      "Epoch 9/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 5ms/step - accuracy: 0.9574 - loss: 0.1377\n",
      "Epoch 10/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 5ms/step - accuracy: 0.9578 - loss: 0.1367\n",
      "Epoch 11/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 5ms/step - accuracy: 0.9607 - loss: 0.1272\n",
      "Epoch 12/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 6ms/step - accuracy: 0.9608 - loss: 0.1277\n",
      "Epoch 13/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 5ms/step - accuracy: 0.9628 - loss: 0.1207\n",
      "Epoch 14/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 5ms/step - accuracy: 0.9631 - loss: 0.1180\n",
      "Epoch 15/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 5ms/step - accuracy: 0.9641 - loss: 0.1157\n",
      "Epoch 16/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 5ms/step - accuracy: 0.9654 - loss: 0.1106\n",
      "Epoch 17/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 5ms/step - accuracy: 0.9656 - loss: 0.1122\n",
      "Epoch 18/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 5ms/step - accuracy: 0.9659 - loss: 0.1090\n",
      "Epoch 19/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 5ms/step - accuracy: 0.9672 - loss: 0.1059\n",
      "Epoch 20/20\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 6ms/step - accuracy: 0.9677 - loss: 0.1041\n",
      "313/313 - 0s - 1ms/step - accuracy: 0.9793 - loss: 0.0682\n",
      "\n",
      "테스트 정확도: 0.9793000221252441\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T05:05:55.737407800Z",
     "start_time": "2026-01-16T05:04:13.397287800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "import pygame\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "### 변수 선언 및 초기화 ###\n",
    "game_mode = \"WAITING\"\n",
    "game_level = 1 # 1 : 초급, 2 : 중급, 3 : 고급(고급은 구상만)\n",
    "answer = 0 # 정답 숫자용 변수\n",
    "quiz_text = '' # answer를 화면에 띄우기 위한 putText용\n",
    "time_limit = 10 # 제한시간 10초\n",
    "start_time = 0 # 시작시간\n",
    "ready_time = 3\n",
    "\n",
    "# 버튼 위치 정의 [x1, y1, x2, y2]\n",
    "btn1_rect = [100, 350, 300, 430] # 초급 버튼\n",
    "btn2_rect = [340, 350, 540, 430] # 중급 버튼\n",
    "\n",
    "# 오답 메시지 관련 변수\n",
    "wrong_msg = False # 오답 메시지 표시할지 말지\n",
    "wrong_msg_time = 0 # 오답 메시지용 time변수\n",
    "wrong_duration = 1.0 # 오답메세지 유지시간\n",
    "\n",
    "# 퀴즈 변수\n",
    "quiz_count = 0      # 현재 몇 번째 문제인지\n",
    "max_quiz = 10       # 총 문제 수\n",
    "total_score = 0.0   # 누적 점수\n",
    "\n",
    "# 마우스 호버효과를 위한 현재 마우스 포지션\n",
    "current_mouse_pos = [0, 0] # [x, y] 좌표 저장\n",
    "\n",
    "# 정,오답 시 이펙트 -> 화면 번쩍임\n",
    "flash_time = 0\n",
    "flash_color = (0,0,0)\n",
    "\n",
    "# floating score 애니메이션\n",
    "score_effects = [] # [{'val': 8.5, 'start_time': t, 'pos': (x, y)}, ...]\n",
    "\n",
    "pygame.mixer.init()\n",
    "media_path = \"C:/Windows/Media/\"\n",
    "sound_correct = pygame.mixer.Sound(media_path + \"Speech On.wav\")\n",
    "sound_wrong = pygame.mixer.Sound(media_path + \"Speech Misrecognition.wav\")\n",
    "\n",
    "try:\n",
    "    model = load_model('tensorflow_model.keras')\n",
    "    print(\"모델 로드 성공!\")\n",
    "except Exception as e:\n",
    "    exit()\n",
    "\n",
    "# 버튼 ui 적용하기\n",
    "def draw_button(img, text, rect, base_color, text_color =(255,255,255)):\n",
    "    x1, y1, x2, y2 = rect\n",
    "    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    draw = ImageDraw.Draw(img_pil)\n",
    "    try:\n",
    "        _font = ImageFont.truetype(\"C:/Windows/Fonts/malgunbd.ttf\", 30)\n",
    "    except:\n",
    "        _font = ImageFont.load_default()\n",
    "\n",
    "    # 1. 외곽선이 있는 둥근 사각형 (버튼 몸체)\n",
    "    draw.rounded_rectangle([x1+3, y1+3, x2+3, y2+3], radius=15, fill=(30, 30, 30)) # 그림자\n",
    "    draw.rounded_rectangle([x1, y1, x2, y2], radius=15, fill=base_color, outline=(255, 255, 255), width=2)\n",
    "\n",
    "    # 2. 텍스트 중앙 정렬 계산\n",
    "    w, h = x2 - x1, y2 - y1\n",
    "    tw, th = draw.textsize(text, font=_font) if hasattr(draw, 'textsize') else (70, 30)\n",
    "    text_pos = (x1 + (w - tw) / 2, y1 + (h - th) / 2 - 5)\n",
    "\n",
    "    # 3. 버튼 텍스트 그리기\n",
    "    draw.text(text_pos, text, font=_font, fill=(255, 255, 255)) # 버튼 글씨는 흰색 고정\n",
    "\n",
    "    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "# 한글 출력을 위해서는 opencv2 프레임을 Pillow로 전환 후, 한글로 그린 뒤에 다시 opencv2에 돌려주는 함수가 필요하다.\n",
    "def print_korean(img, text, pos, f_size, _color):\n",
    "    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    draw = ImageDraw.Draw(img_pil)\n",
    "    try:\n",
    "        _font = ImageFont.truetype(\"C:/Windows/Fonts/malgun.ttf\", f_size)\n",
    "    except Exception as e:\n",
    "        _font = ImageFont.load_default()\n",
    "        print(f\"error : {e}\")\n",
    "\n",
    "    # 글씨 외곽선 그리기\n",
    "    x, y = pos\n",
    "    stroke_color = (0, 0, 0) # 검은색 외곽선\n",
    "    for adj in range(0, 2): # 두께 조절 (2픽셀)\n",
    "        draw.text((x+adj, y), text, font=_font, fill=stroke_color)\n",
    "        draw.text((x, y+adj), text, font=_font, fill=stroke_color)\n",
    "\n",
    "    draw.text(pos,text, font=_font, fill=_color)\n",
    "    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGRA)\n",
    "\n",
    "### 난이도 선택을 위한 마우스 콜백\n",
    "def mouse_callback(event, _x, _y, _flags, _param):\n",
    "    global game_mode, game_level, start_time,current_mouse_pos\n",
    "    # 마우스가 움직일 때마다 좌표 업데이트\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        current_mouse_pos = [_x, _y]\n",
    "    if event == cv2.EVENT_LBUTTONDOWN and game_mode == \"WAITING\":\n",
    "        if (btn1_rect[0] < _x < btn1_rect[2]) and (btn1_rect[1] < _y < btn1_rect[3]):\n",
    "            game_level = 1\n",
    "            game_init()\n",
    "            game_mode = \"READY\"\n",
    "            print(\"초급\")\n",
    "        elif (btn2_rect[0] < _x < btn2_rect[2]) and (btn2_rect[1] < _y < btn2_rect[3]):\n",
    "            game_level = 2\n",
    "            game_init()\n",
    "            game_mode = \"READY\"\n",
    "            print(\"중급\")\n",
    "        else: # 난이도 고급\n",
    "            pass\n",
    "\n",
    "### 퀴즈 메소드\n",
    "def quiz_fuc(lv):\n",
    "    global answer, quiz_text\n",
    "    if lv == 1: # 초급\n",
    "        answer = random.randint(1,9) # 1~9까지 숫자 랜덤\n",
    "        quiz_text = \"숫자 : \" + str(answer)\n",
    "        print(quiz_text)\n",
    "        pass\n",
    "    elif lv == 2: # 중급\n",
    "        op = random.choice(['+', '-'])\n",
    "        if op == '+':\n",
    "            a = random.randint(1, 8)\n",
    "            b = random.randint(1, 9-a) # 합이 9가 넘지 않도록, a 기반으로 랜덤\n",
    "            answer = a + b\n",
    "        else:\n",
    "            a = random.randint(2, 9)\n",
    "            b = random.randint(1, a-1) # 합이 음수가 되지않올고 a보다 작은 숫자만 나오도록\n",
    "            answer = a - b\n",
    "        quiz_text = f\"QUIZ : {a} {op} {b} = ?\" # ex) 5 + 4 = ? / 9 - 4 = ?\n",
    "        print(quiz_text)\n",
    "    elif lv == 3: # 고급\n",
    "        print(\"여긴 아이디어의 단계입니다.\")\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "def game_init():\n",
    "    global quiz_count, total_score, start_time\n",
    "    quiz_count = 1\n",
    "    total_score = 0.0\n",
    "    quiz_fuc(game_level)\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "window_name = \"Tensorflow Game\"\n",
    "cv2.namedWindow(window_name)\n",
    "cv2.setMouseCallback(window_name, mouse_callback)\n",
    "###\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"웹캠을 열 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "###\n",
    "while True:\n",
    "    ret, frame = cap.read() # 리턴값과 프레임\n",
    "    if not ret: # false면\n",
    "        print(\"프레임을 가져 올 수 없습니다.\")\n",
    "        break\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    flip_frame = cv2.flip(frame, 1) # y축을 기준으로 뒤집어 주세요 -> 거울 반전\n",
    "    height, width, color = frame.shape # 높이, 폭, color인데 color는 딱히 안쓸거임\n",
    "    center_x, center_y = width // 2, height // 2 # x와 y의 중심점\n",
    "\n",
    "    offset_y = 60 # 화면 위아래 조절하려고 만든 변수\n",
    "    roi = flip_frame[center_y - 150 + offset_y : center_y + 150 + offset_y, center_x - 150:center_x + 150]    # roi 영역 만들기\n",
    "    # #x,y중심점을 기준으로 150씩의 거리를 가진 영역 만들기 -> 300x300\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    # game_mode 구현.\n",
    "    if game_mode == \"WAITING\": # 난이도 선택\n",
    "        flip_frame = print_korean(flip_frame, \"숫자 맞추기 게임\", (center_x-160, center_y-200), 40, (0,0,0))\n",
    "        flip_frame = print_korean(flip_frame, \"난이도를 정하세요 [ 초급, 중급 ]\", (center_x-220, center_y-130), 30, (255,255,0))\n",
    "\n",
    "        mx, my = current_mouse_pos # 현재 마우스 좌표\n",
    "\n",
    "        # 초급 버튼 호버효과 - 더 밝은 보라색\n",
    "        if (btn1_rect[0] < mx < btn1_rect[2]) and (btn1_rect[1] < my < btn1_rect[3]):\n",
    "            flip_frame = draw_button(flip_frame, \"초 급\", btn1_rect, (200, 100, 255))\n",
    "        else:\n",
    "            flip_frame = draw_button(flip_frame, \"초 급\", btn1_rect, (150, 50, 200))\n",
    "        # 중급 버튼 호버효과 - 더 밝은 청록색\n",
    "        if (btn2_rect[0] < mx < btn2_rect[2]) and (btn2_rect[1] < my < btn2_rect[3]):\n",
    "            flip_frame = draw_button(flip_frame, \"중 급\", btn2_rect, (100, 220, 220))\n",
    "        else:\n",
    "            flip_frame = draw_button(flip_frame, \"중 급\", btn2_rect, (50, 150, 150))\n",
    "    elif game_mode == \"READY\":\n",
    "        flip_frame = print_korean(flip_frame, \"게임이 곧 시작됩니다!!!\", (center_x-215, center_y-120), 40, (255,0,0))\n",
    "\n",
    "        delay_time = time.time() - start_time\n",
    "        count = int(ready_time - delay_time) + 1\n",
    "        if count > 0:\n",
    "            flip_frame = print_korean(flip_frame, str(count), (center_x - 15, center_y - 25), 50, (255,0,0))\n",
    "        else:\n",
    "            start_time = time.time()\n",
    "            game_mode = \"PLAYING\"\n",
    "\n",
    "\n",
    "    elif game_mode == \"PLAYING\":\n",
    "        cv2.rectangle(flip_frame, (center_x - 150, center_y - 150 + offset_y),\n",
    "                  (center_x + 150, center_y + 150 + offset_y), (0,0,255), 2) # 외곽선 그리기\n",
    "\n",
    "        delay_time = time.time() - start_time\n",
    "        remain_time = max(0, time_limit - delay_time)\n",
    "\n",
    "        # 상단 정보 표시\n",
    "        flip_frame = print_korean(flip_frame, quiz_text, (0, 60), 40, (255, 255, 0))\n",
    "        flip_frame = print_korean(flip_frame, f\"남은 시간: {remain_time:.1f}초\", (0, 110), 30, (0, 0, 255))\n",
    "        # 2. 진행 상황 표시 (중상단)\n",
    "        flip_frame = print_korean(flip_frame, f\"{quiz_count} / {max_quiz}\", (center_x - 50, 20), 35, (255, 255, 255))\n",
    "        # 3. 실시간 점수 표시 (우상단)\n",
    "        flip_frame = print_korean(flip_frame, f\"SCORE: {total_score:.1f}\", (width - 220, 20), 35, (0, 255, 0))\n",
    "\n",
    "        if wrong_msg: # 오답메세지를 출력했는지 확인\n",
    "            if time.time() - wrong_msg_time < wrong_duration:\n",
    "                flip_frame = print_korean(flip_frame, \"오답!\", (width-100, 100), 30, (255,0,0))\n",
    "        else:\n",
    "            wrong_time = False\n",
    "\n",
    "        if key == ord('c') or key == ord('C'):\n",
    "            correct_roi = cv2.flip(roi, 1)\n",
    "            gray_image = cv2.cvtColor(correct_roi, cv2.COLOR_BGR2GRAY)\n",
    "            gauss_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "            _, otsu_thread = cv2.threshold(gauss_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "            contours, _ = cv2.findContours(otsu_thread, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            if contours:\n",
    "                cnt = max(contours, key=cv2.contourArea)\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                digit = otsu_thread[y:y+h, x:x+w]\n",
    "\n",
    "                kernel = np.ones((3, 3), np.uint8)\n",
    "                digit = cv2.dilate(digit, kernel, iterations=1)\n",
    "\n",
    "                target_size = 18\n",
    "                if w > h:\n",
    "                    new_w = target_size\n",
    "                    new_h = int(h * (target_size / w))\n",
    "                else:\n",
    "                    new_h = target_size\n",
    "                    new_w = int(w * (target_size / h))\n",
    "\n",
    "                digit_resized = cv2.resize(digit, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                final_img = np.zeros((28, 28), dtype=np.uint8)\n",
    "                start_x = (28 - new_w) // 2\n",
    "                start_y = (28 - new_h) // 2\n",
    "                final_img[start_y:start_y+new_h, start_x:start_x+new_w] = digit_resized\n",
    "\n",
    "                final_img = cv2.GaussianBlur(final_img, (3, 3), 0)\n",
    "                resized_img = final_img\n",
    "            else:\n",
    "                resized_img = np.zeros((28, 28), dtype=np.uint8)\n",
    "\n",
    "            cv2.imshow('What AI Sees', resized_img)\n",
    "            test_data = resized_img.reshape(1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "            try:\n",
    "                pred_img = model.predict(test_data , verbose=0)\n",
    "                result = np.argmax(pred_img)\n",
    "                print(f\"인식 결과 : {result}, 정답 : {answer}\")\n",
    "\n",
    "                # print(\"Raw Sofxmax:\", pred_img[0])\n",
    "                # print(\"Prediced Class:\", np.argmax(pred_img[0]))\n",
    "                # print(\"Confidence:\", np.max(pred_img[0]))\n",
    "\n",
    "                if result == answer:\n",
    "                   print(\"정답!\")\n",
    "                   wrong_msg = False\n",
    "                   sound_correct.play()\n",
    "\n",
    "                   total_score += remain_time\n",
    "                   plus_score = remain_time\n",
    "\n",
    "                   # floating score\n",
    "                   score_effects.append({\n",
    "                       'val': plus_score,\n",
    "                       'start_time': time.time(),\n",
    "                       'x': width - 150, # SCORE 표시 근처\n",
    "                       'y': 60\n",
    "                   })\n",
    "                   # 화면 반짝임\n",
    "                   flash_color = (0, 255, 0) # 초록색\n",
    "                   flash_time = time.time()\n",
    "\n",
    "                   if quiz_count >= max_quiz:\n",
    "                       game_mode = \"END\"\n",
    "                   else:\n",
    "                       quiz_count += 1\n",
    "                       quiz_fuc(game_level) # 다음 문제 생성\n",
    "                       start_time = time.time() # 시간 초기화\n",
    "                else:\n",
    "                   print(\"오답!\")\n",
    "                   wrong_msg = True\n",
    "                   sound_wrong.play()\n",
    "\n",
    "                   flash_color = (0, 0, 255) # 빨간색\n",
    "                   flash_time = time.time()\n",
    "\n",
    "                   wrong_msg_time = time.time() #c연타해도 마지막 기준 1초 동안 메세지 출력하도록\n",
    "            except Exception as e:\n",
    "                print(f\"error : {e}\")\n",
    "        if remain_time <= 0 :\n",
    "            if quiz_count >= max_quiz:\n",
    "                game_mode = \"END\"\n",
    "            else:\n",
    "                quiz_count += 1\n",
    "                quiz_fuc(game_level)\n",
    "                start_time = time.time()\n",
    "\n",
    "    elif game_mode == \"END\":\n",
    "        level_str = \"초급\" if game_level == 1 else \"중급\"\n",
    "        flip_frame = print_korean(flip_frame, \"GAME OVER\", (center_x - 120, center_y - 120), 50, (0, 0, 255))\n",
    "        flip_frame = print_korean(flip_frame, f\"난이도 : {level_str}\", (center_x - 100, center_y - 40), 30, (255, 255, 255))\n",
    "        flip_frame = print_korean(flip_frame, f\"최종 점수 : {total_score:.1f}점\", (center_x - 120, center_y + 10), 35, (0, 255, 255))\n",
    "        flip_frame = print_korean(flip_frame, \"Enter를 눌러 메인으로\", (center_x - 140, center_y + 80), 25, (200, 200, 200))\n",
    "\n",
    "        if key == 13: # 엔터\n",
    "            game_mode = \"WAITING\"\n",
    "\n",
    "    # Floating Score 애니메이션\n",
    "    curr_t = time.time()\n",
    "    for effect in score_effects[:]:\n",
    "        elapsed = curr_t - effect['start_time']\n",
    "        if elapsed > 1.0: # 1초 지나면 사라짐\n",
    "            score_effects.remove(effect)\n",
    "            continue\n",
    "\n",
    "        # y값은 위로(-), 투명도는 낮게 계산\n",
    "        move_up = int(elapsed * 60)\n",
    "        # print_korean 함수를 써서 출력\n",
    "        flip_frame = print_korean(flip_frame,\n",
    "                                  f\"+{effect['val']:.1f}\", (effect['x'], effect['y'] - move_up), 30, (0, 255, 255))\n",
    "\n",
    "\n",
    "    # 화면 번쩍임을 화면에 그리기\n",
    "    if time.time() - flash_time < 0.2: # 0.2초 동안만 번쩍\n",
    "        overlay = flip_frame.copy()\n",
    "        cv2.rectangle(overlay, (0, 0), (width, height), flash_color, -1)\n",
    "        # addWeighted로 투명도 조절 (0.3은 30% 농도)\n",
    "        flip_frame = cv2.addWeighted(overlay, 0.3, flip_frame, 0.7, 0)\n",
    "\n",
    "    cv2.imshow(window_name, flip_frame)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "294a6bf17255d420",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로드 성공!\n",
      "숫자 : 4\n",
      "초급\n",
      "인식 결과 : 4, 정답 : 4\n",
      "정답!\n",
      "숫자 : 8\n",
      "인식 결과 : 8, 정답 : 8\n",
      "정답!\n",
      "숫자 : 1\n",
      "인식 결과 : 1, 정답 : 1\n",
      "정답!\n",
      "숫자 : 3\n",
      "인식 결과 : 3, 정답 : 3\n",
      "정답!\n",
      "숫자 : 3\n",
      "인식 결과 : 3, 정답 : 3\n",
      "정답!\n",
      "숫자 : 3\n",
      "인식 결과 : 3, 정답 : 3\n",
      "정답!\n",
      "숫자 : 7\n",
      "인식 결과 : 7, 정답 : 7\n",
      "정답!\n",
      "숫자 : 3\n",
      "인식 결과 : 3, 정답 : 3\n",
      "정답!\n",
      "숫자 : 5\n",
      "인식 결과 : 8, 정답 : 5\n",
      "오답!\n",
      "인식 결과 : 4, 정답 : 5\n",
      "오답!\n",
      "인식 결과 : 5, 정답 : 5\n",
      "정답!\n",
      "숫자 : 4\n",
      "인식 결과 : 4, 정답 : 4\n",
      "정답!\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-16T03:55:24.018212100Z",
     "start_time": "2026-01-16T03:43:58.718929500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 데이터 로드 및 4차원 변형\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape(-1, 28, 28, 1) / 255.0\n",
    "test_images = test_images.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "# 증강 설정 강화 (실제 웹캠 환경에 맞춤)\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# CNN 모델 구조 (인식률 대폭 향상)\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    keras.layers.BatchNormalization(), # 추가: 데이터 정규화\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(), # 추가\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.3), # Dropout 상향\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 증강 데이터로 더 많이 학습 (CNN은 데이터가 많이 필요함)\n",
    "model.fit(datagen.flow(train_images, train_labels, batch_size=64), epochs=30)\n",
    "\n",
    "model.save('tensorflow_model_cnn.keras')"
   ],
   "id": "9d3a759403c9de6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 22ms/step - accuracy: 0.8165 - loss: 0.5768\n",
      "Epoch 2/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 25ms/step - accuracy: 0.9331 - loss: 0.2208\n",
      "Epoch 3/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 25ms/step - accuracy: 0.9480 - loss: 0.1754\n",
      "Epoch 4/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 25ms/step - accuracy: 0.9564 - loss: 0.1501\n",
      "Epoch 5/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 24ms/step - accuracy: 0.9592 - loss: 0.1356\n",
      "Epoch 6/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 24ms/step - accuracy: 0.9641 - loss: 0.1233\n",
      "Epoch 7/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 25ms/step - accuracy: 0.9663 - loss: 0.1173\n",
      "Epoch 8/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 24ms/step - accuracy: 0.9676 - loss: 0.1116\n",
      "Epoch 9/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 24ms/step - accuracy: 0.9694 - loss: 0.1057\n",
      "Epoch 10/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 25ms/step - accuracy: 0.9703 - loss: 0.1015\n",
      "Epoch 11/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 24ms/step - accuracy: 0.9717 - loss: 0.0962\n",
      "Epoch 12/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 24ms/step - accuracy: 0.9739 - loss: 0.0919\n",
      "Epoch 13/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 24ms/step - accuracy: 0.9733 - loss: 0.0890\n",
      "Epoch 14/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 25ms/step - accuracy: 0.9750 - loss: 0.0864\n",
      "Epoch 15/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 24ms/step - accuracy: 0.9764 - loss: 0.0815\n",
      "Epoch 16/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 24ms/step - accuracy: 0.9775 - loss: 0.0815\n",
      "Epoch 17/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 24ms/step - accuracy: 0.9770 - loss: 0.0780\n",
      "Epoch 18/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 24ms/step - accuracy: 0.9769 - loss: 0.0790\n",
      "Epoch 19/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 25ms/step - accuracy: 0.9778 - loss: 0.0769\n",
      "Epoch 20/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 24ms/step - accuracy: 0.9786 - loss: 0.0737\n",
      "Epoch 21/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 25ms/step - accuracy: 0.9782 - loss: 0.0743\n",
      "Epoch 22/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 24ms/step - accuracy: 0.9798 - loss: 0.0703\n",
      "Epoch 23/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 24ms/step - accuracy: 0.9787 - loss: 0.0738\n",
      "Epoch 24/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 24ms/step - accuracy: 0.9788 - loss: 0.0738\n",
      "Epoch 25/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 25ms/step - accuracy: 0.9807 - loss: 0.0674\n",
      "Epoch 26/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 24ms/step - accuracy: 0.9810 - loss: 0.0653\n",
      "Epoch 27/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 24ms/step - accuracy: 0.9811 - loss: 0.0649\n",
      "Epoch 28/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 24ms/step - accuracy: 0.9814 - loss: 0.0647\n",
      "Epoch 29/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 24ms/step - accuracy: 0.9810 - loss: 0.0653\n",
      "Epoch 30/30\n",
      "\u001B[1m938/938\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 25ms/step - accuracy: 0.9825 - loss: 0.0634\n"
     ]
    }
   ],
   "execution_count": 78
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
